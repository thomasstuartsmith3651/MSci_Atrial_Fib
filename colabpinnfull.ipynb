{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFFakHSVwGvlk60/h90wXU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thomasstuartsmith3651/MSci_Atrial_Fib/blob/main/colabpinnfull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfeA6oZp_9BZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Parameters\n",
        "num_impulses = 500  # Number of training samples\n",
        "start_positions = np.random.uniform(-1, 1, num_impulses)\n",
        "positions_to_record = np.array([2, 4, 6, 8])\n",
        "speed = 1.0\n",
        "# Lists to store speeds and change positions for each impulse\n",
        "speeds_list = []\n",
        "change_positions_list = []\n",
        "\n",
        "# Function to compute activation time considering speed changes\n",
        "def compute_activation_time(start_pos, xi, speeds, change_positions):\n",
        "    x_points = [start_pos, *change_positions, xi]\n",
        "    t = 0.0\n",
        "    for i in range(3):\n",
        "        x0 = x_points[i]\n",
        "        x1 = x_points[i+1]\n",
        "        if x1 <= x0:\n",
        "            continue  # Skip if x1 is not ahead of x0\n",
        "        distance = x1 - x0\n",
        "        t += distance / speeds[i]\n",
        "    return t\n",
        "\n",
        "# Generate activation times data\n",
        "activation_times_data = []\n",
        "\n",
        "# Define the number of bins for stratification\n",
        "num_bins = 10\n",
        "bin_edges = np.linspace(2, 8, num_bins + 1)\n",
        "num_conduction = 2\n",
        "for idx in range(num_impulses):\n",
        "    while True:\n",
        "        # Generate two change positions using stratified sampling\n",
        "        bins = np.random.choice(range(num_bins), size=num_conduction, replace=False)\n",
        "        change_positions = []\n",
        "        for bin_index in bins:\n",
        "            # Randomly select a position within the bin\n",
        "            bin_start = bin_edges[bin_index]\n",
        "            bin_end = bin_edges[bin_index + 1]\n",
        "            pos = np.random.uniform(bin_start, bin_end)\n",
        "            change_positions.append(pos)\n",
        "        change_positions = np.sort(change_positions)\n",
        "        # Ensure the two change positions are sufficiently apart\n",
        "        min_separation = 0.5  # Increased from 0.5 to 1.5\n",
        "        if abs(change_positions[1] - change_positions[0]) >= min_separation:\n",
        "            break\n",
        "    change_positions_list.append(change_positions)\n",
        "    speeds = [speed]\n",
        "\n",
        "    # Assign random speeds for each segment\n",
        "    speed_multiplier = np.random.uniform(0.2, 3.0, num_conduction)\n",
        "    for i in range(len(speed_multiplier)):\n",
        "        speeds.append(speed*speed_multiplier)\n",
        "    speeds_list.append(speeds)\n",
        "\n",
        "    start_pos = start_positions[idx]\n",
        "\n",
        "    # Compute activation times at positions_to_record\n",
        "    activation_times = []\n",
        "    for xi in positions_to_record:\n",
        "        time = compute_activation_time(start_pos, xi, speeds, change_positions)\n",
        "        activation_times.append(time)\n",
        "    activation_times_data.append(activation_times)\n",
        "\n",
        "# Save activation times data\n",
        "activation_times_data = np.array(activation_times_data)\n",
        "np.save('activation_times.npy', activation_times_data)\n",
        "\n",
        "# Save speeds and change_positions for reference\n",
        "np.save('speeds_list.npy', speeds_list)\n",
        "np.save('change_positions_list.npy', change_positions_list)\n",
        "\n",
        "# Save start_positions\n",
        "np.save('start_positions.npy', start_positions)\n",
        "\n",
        "# Optional: Visualize the distributions\n",
        "def visualize_distributions():\n",
        "    # Load change_positions_list\n",
        "    change_positions_array = np.array(change_positions_list)\n",
        "\n",
        "    # Plot histograms of the change positions\n",
        "    # plt.figure(figsize=(10, 4))\n",
        "\n",
        "    # plt.subplot(1, 2, 1)\n",
        "    # plt.hist(change_positions_array[:, 0], bins=bin_edges, edgecolor='black')\n",
        "    # plt.title('Distribution of First Change Position')\n",
        "    # plt.xlabel('Position')\n",
        "    # plt.ylabel('Frequency')\n",
        "\n",
        "    # plt.subplot(1, 2, 2)\n",
        "    # plt.hist(change_positions_array[:, 1], bins=bin_edges, edgecolor='black')\n",
        "    # plt.title('Distribution of Second Change Position')\n",
        "    # plt.xlabel('Position')\n",
        "    # plt.ylabel('Frequency')\n",
        "\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    # Load speeds_list\n",
        "    speeds_array = np.array(speeds_list)\n",
        "\n",
        "    # Plot histograms of the speeds\n",
        "    plt.figure(figsize=(10, 4))\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.hist(speeds_array[:, i], bins=20, range=(0.5, 2.0), edgecolor='black')\n",
        "        plt.title(f'Distribution of Speed {i+1}')\n",
        "        plt.xlabel('Speed')\n",
        "        plt.ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Uncomment the line below to visualize the distributions\n",
        "    # visualize_distributions()\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Create the 'pinnplot' directory if it doesn't exist\n",
        "if not os.path.exists('pinnplot'):\n",
        "    os.makedirs('pinnplot')\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Load training data\n",
        "activation_times_data = np.load('activation_times.npy')\n",
        "positions_to_record = np.array([2.0, 4.0, 6.0, 8.0])\n",
        "\n",
        "# Load speeds, change positions, and start positions\n",
        "speeds_list = np.load('speeds_list.npy', allow_pickle=True)\n",
        "change_positions_list = np.load('change_positions_list.npy', allow_pickle=True)\n",
        "start_positions = np.load('start_positions.npy')\n",
        "\n",
        "# Prepare training data\n",
        "inputs = activation_times_data[:, :4]  # Four activation times at positions 2, 4, 6, 8\n",
        "inputs = torch.tensor(inputs, dtype=torch.float32)  # Shape: [num_samples, 4]\n",
        "\n",
        "# We will interpolate activation times at positions between 2 and 8\n",
        "interp_positions = np.linspace(2, 8, 200)\n",
        "interp_positions_tensor = torch.tensor(interp_positions, dtype=torch.float32).unsqueeze(0).repeat(inputs.shape[0], 1)  # Shape: [num_samples, num_points]\n",
        "\n",
        "# Define the PINN with adjusted neurons per layer\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PINN, self).__init__()\n",
        "        # Reduced neurons per layer to 32\n",
        "        self.fc1 = nn.Linear(4 + 1, 64)\n",
        "        self.fc2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.ReLU()\n",
        "        self.fc5 = nn.Linear(64, 64)\n",
        "        self.fc6 = nn.ReLU()\n",
        "        self.fc7 = nn.Linear(64, 64)\n",
        "        self.fc8 = nn.ReLU()\n",
        "        self.fc9 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x, activation_times):\n",
        "        # x: [batch_size, num_points]\n",
        "        # activation_times: [batch_size, 4]\n",
        "        activation_times_expanded = activation_times.unsqueeze(1).expand(-1, x.shape[1], -1)  # [batch_size, num_points, 4]\n",
        "        x_expanded = x.unsqueeze(-1)  # [batch_size, num_points, 1]\n",
        "        input = torch.cat([activation_times_expanded, x_expanded], dim=2)  # [batch_size, num_points, 5]\n",
        "        out = self.fc1(input)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.fc5(out)\n",
        "        out = self.fc6(out)\n",
        "        out = self.fc7(out)\n",
        "        out = self.fc8(out)\n",
        "        out = self.fc9(out)\n",
        "        return out.squeeze(-1)  # [batch_size, num_points]\n",
        "\n",
        "# Loss function with data loss and eikonal residual\n",
        "def loss_function(model, x_interp, activation_times, positions_known, speeds_batch, change_positions_batch, weight_eikonal=0.01):\n",
        "    # Predictions at interpolated positions\n",
        "    activation_times_pred = model(x_interp, activation_times)  # Shape: [batch_size, num_points]\n",
        "\n",
        "    # Data loss at known positions (positions_known)\n",
        "    positions_known_tensor = torch.tensor(positions_known, dtype=torch.float32).unsqueeze(0)  # Shape: [1, 4]\n",
        "    positions_known_tensor = positions_known_tensor.expand(activation_times.shape[0], -1)  # Shape: [batch_size, 4]\n",
        "\n",
        "    activation_times_pred_known = model(positions_known_tensor, activation_times)  # Shape: [batch_size, 4]\n",
        "    data_loss = nn.MSELoss()(activation_times_pred_known, activation_times)  # Scalar\n",
        "\n",
        "    # Eikonal residual over interpolated positions\n",
        "    x_interp.requires_grad_(True)\n",
        "    activation_times_pred = model(x_interp, activation_times)\n",
        "    grad_activation_times = torch.autograd.grad(\n",
        "        outputs=activation_times_pred,\n",
        "        inputs=x_interp,\n",
        "        grad_outputs=torch.ones_like(activation_times_pred),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]  # Shape: [batch_size, num_points]\n",
        "\n",
        "    # Compute speed c(x) for each sample in the batch\n",
        "    c_list = []\n",
        "    for i in range(x_interp.shape[0]):  # batch_size\n",
        "        x = x_interp[i]  # Shape: [num_points]\n",
        "        speeds = speeds_batch[i]  # Shape: [3]\n",
        "        change_positions = change_positions_batch[i]  # Shape: [2]\n",
        "\n",
        "        # Define speed function for this sample\n",
        "        c = torch.zeros_like(x)\n",
        "        c = torch.where(x < change_positions[0], speeds[0], c)\n",
        "        c = torch.where((x >= change_positions[0]) & (x < change_positions[1]), speeds[1], c)\n",
        "        c = torch.where(x >= change_positions[1], speeds[2], c)\n",
        "        c_list.append(c)\n",
        "\n",
        "    c = torch.stack(c_list, dim=0)  # Shape: [batch_size, num_points]\n",
        "\n",
        "    # Eikonal residual\n",
        "    eikonal_residual = (((grad_activation_times * c) - 1.0) ** 2).mean()  # Scalar\n",
        "\n",
        "    # Total loss: weighted sum of data loss and eikonal residual\n",
        "    total_loss = data_loss*1.3 + weight_eikonal * eikonal_residual\n",
        "    return total_loss, data_loss.item(), eikonal_residual.item()\n",
        "\n",
        "# Initialize model and optimizer\n",
        "model = PINN()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)  # Using AdamW optimizer with weight decay\n",
        "\n",
        "# Prepare speeds and change positions as tensors\n",
        "speeds_tensor = torch.tensor(speeds_list.tolist(), dtype=torch.float32)  # Shape: [num_samples, 3]\n",
        "change_positions_tensor = torch.tensor(change_positions_list.tolist(), dtype=torch.float32)  # Shape: [num_samples, 2]\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 4000  # Reduced from 7000 to 2000\n",
        "batch_size = 32  # Adjusted batch size\n",
        "num_samples = inputs.shape[0]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    permutation = torch.randperm(num_samples)\n",
        "    epoch_total_loss = 0.0\n",
        "    epoch_data_loss = 0.0\n",
        "    epoch_eikonal_loss = 0.0\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        activation_times_batch = inputs[indices]  # Shape: [batch_size, 4]\n",
        "        x_batch = interp_positions_tensor[indices]  # Shape: [batch_size, num_points]\n",
        "        speeds_batch = speeds_tensor[indices]  # Shape: [batch_size, 3]\n",
        "        change_positions_batch = change_positions_tensor[indices]  # Shape: [batch_size, 2]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss, data_loss_value, eikonal_loss_value = loss_function(\n",
        "            model, x_batch, activation_times_batch, positions_to_record, speeds_batch, change_positions_batch, weight_eikonal=0.01\n",
        "        )\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Sum losses over batches\n",
        "        epoch_total_loss += total_loss.item()\n",
        "        epoch_data_loss += data_loss_value\n",
        "        epoch_eikonal_loss += eikonal_loss_value\n",
        "\n",
        "    # Average losses over the number of batches\n",
        "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
        "    avg_total_loss = epoch_total_loss / num_batches\n",
        "    avg_data_loss = epoch_data_loss / num_batches\n",
        "    avg_eikonal_loss = epoch_eikonal_loss / num_batches\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Total Loss: {avg_total_loss:.6f}, Data Loss: {avg_data_loss:.6f}, Eikonal Loss: {avg_eikonal_loss:.6f}\")\n",
        "\n",
        "# Function to compute activation time\n",
        "def compute_activation_time(start_pos, xi, speeds, change_positions):\n",
        "    x_points = [start_pos, *change_positions, xi]\n",
        "    t = 0.0\n",
        "    for i in range(3):\n",
        "        x0 = x_points[i]\n",
        "        x1 = x_points[i+1]\n",
        "        if x1 <= x0:\n",
        "            continue  # Skip if x1 is not ahead of x0\n",
        "        distance = x1 - x0\n",
        "        t += distance / speeds[i]\n",
        "    return t\n",
        "\n",
        "# Plot the activation times from positions 2 to 8 for multiple samples\n",
        "def plot_training_samples(sample_indices):\n",
        "    for sample_idx in sample_indices:\n",
        "        with torch.no_grad():\n",
        "            activation_times_sample = inputs[sample_idx:sample_idx+1]  # Shape: [1, 4]\n",
        "            x_sample = interp_positions_tensor[sample_idx:sample_idx+1]  # Shape: [1, num_points]\n",
        "            activation_times_pred = model(x_sample, activation_times_sample).squeeze(0).numpy()\n",
        "            x_sample_np = x_sample.squeeze(0).numpy()\n",
        "\n",
        "            # Get the actual speeds and change positions for the sample\n",
        "            speeds_sample = speeds_tensor[sample_idx].numpy()\n",
        "            change_positions_sample = change_positions_tensor[sample_idx].numpy()\n",
        "\n",
        "            # Get the starting position for the sample\n",
        "            start_pos_sample = start_positions[sample_idx]\n",
        "\n",
        "            # Compute true activation times across interp_positions\n",
        "            true_activation_times = []\n",
        "            for xi in x_sample_np:\n",
        "                time = compute_activation_time(start_pos_sample, xi, speeds_sample, change_positions_sample)\n",
        "                true_activation_times.append(time)\n",
        "            true_activation_times = np.array(true_activation_times)\n",
        "\n",
        "            # Print speeds and change positions\n",
        "            print(f\"Sample {sample_idx} - Speeds: {speeds_sample}, Change Positions: {change_positions_sample}\")\n",
        "\n",
        "        # Plotting\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(x_sample_np, activation_times_pred, label='Predicted Activation Times', linestyle='--')\n",
        "        plt.plot(x_sample_np, true_activation_times, label='True Activation Times', linestyle='-')\n",
        "        plt.scatter(positions_to_record, activation_times_sample.squeeze(0).numpy(), color='red', label='Input Activation Times')\n",
        "        # Plot vertical lines at speed change positions\n",
        "        for idx_cp, pos in enumerate(change_positions_sample):\n",
        "            plt.axvline(x=pos, color='grey', linestyle=':', label='Speed Change Point' if idx_cp == 0 else \"\")\n",
        "            plt.plot(pos, compute_activation_time(start_pos_sample, pos, speeds_sample, change_positions_sample), 'x', color='black')\n",
        "        plt.xlabel('Position')\n",
        "        plt.ylabel('Activation Time')\n",
        "        plt.title(f'Training Sample {sample_idx} - Activation Times with Variable Speeds')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        # Save the plot\n",
        "        plt.savefig(f'pinnplot/training_sample_{sample_idx}64datfast.png')\n",
        "        plt.close()\n",
        "\n",
        "# Plot activation times for multiple samples\n",
        "sample_indices_to_plot = [0, 10, 20, 30, 40]  # Adjust indices based on printed change positions\n",
        "plot_training_samples(sample_indices_to_plot)\n",
        "\n",
        "# Visualize distributions of speeds and change positions\n",
        "def visualize_distributions():\n",
        "    # Convert lists to arrays\n",
        "    speeds_array = np.array(speeds_list)\n",
        "    change_positions_array = np.array(change_positions_list)\n",
        "\n",
        "    # Plot histograms of the speeds\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.hist(speeds_array[:, i], bins=20, range=(0.5, 2.0), edgecolor='black')\n",
        "        plt.title(f'Distribution of Speed {i+1}')\n",
        "        plt.xlabel('Speed')\n",
        "        plt.ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('pinnplot/speeds_distribution64datfast.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Plot histograms of the change positions\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(change_positions_array[:, 0], bins=20, range=(2, 8), edgecolor='black')\n",
        "    plt.title('Distribution of First Change Position')\n",
        "    plt.xlabel('Position')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(change_positions_array[:, 1], bins=20, range=(2, 8), edgecolor='black')\n",
        "    plt.title('Distribution of Second Change Position')\n",
        "    plt.xlabel('Position')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('pinnplot/change_positions_distribution64datfast.png')\n",
        "    plt.close()\n",
        "\n",
        "# Call the function to visualize distributions\n",
        "visualize_distributions()\n",
        "\n",
        "# Testing with specific data\n",
        "# Set new start position for the impulse\n",
        "new_start_pos = 0.0  # Adjust as needed\n",
        "\n",
        "# Set specific change positions at 3.3 and 6.5\n",
        "new_change_positions = np.array([3.3, 6.5])\n",
        "print(f\"New change positions: {new_change_positions}\")\n",
        "\n",
        "# Assign significantly different speeds to make the changes noticeable\n",
        "new_speeds = np.array([0.5, 2.0, 0.3])  # Adjusted to make speed changes more pronounced\n",
        "print(f\"New speeds: {new_speeds}\")\n",
        "\n",
        "# Compute activation times at known positions\n",
        "positions_known = positions_to_record\n",
        "new_activation_times = []\n",
        "for xi in positions_known:\n",
        "    time = compute_activation_time(new_start_pos, xi, new_speeds, new_change_positions)\n",
        "    new_activation_times.append(time)\n",
        "new_activation_times_tensor = torch.tensor(new_activation_times, dtype=torch.float32).unsqueeze(0)  # Shape: [1, 4]\n",
        "\n",
        "# Prepare x_sample for testing\n",
        "x_sample_np = interp_positions  # Use the same interpolated positions\n",
        "x_sample_test = torch.tensor(x_sample_np, dtype=torch.float32).unsqueeze(0)  # Shape: [1, num_points]\n",
        "\n",
        "with torch.no_grad():\n",
        "    activation_times_pred = model(x_sample_test, new_activation_times_tensor).squeeze(0).numpy()\n",
        "\n",
        "    # Compute true activation times across interp_positions for testing\n",
        "    true_activation_times_test = []\n",
        "    for xi in x_sample_np:\n",
        "        time = compute_activation_time(new_start_pos, xi, new_speeds, new_change_positions)\n",
        "        true_activation_times_test.append(time)\n",
        "    true_activation_times_test = np.array(true_activation_times_test)\n",
        "\n",
        "# Plotting for testing data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x_sample_np, activation_times_pred, label='Predicted Activation Times', linestyle='--')\n",
        "plt.plot(x_sample_np, true_activation_times_test, label='True Activation Times', linestyle='-')\n",
        "plt.scatter(positions_known, new_activation_times, color='green', label='New Input Activation Times')\n",
        "# Plot vertical lines at speed change positions and add markers\n",
        "for idx, pos in enumerate(new_change_positions):\n",
        "    plt.axvline(x=pos, color='grey', linestyle=':', label='Speed Change Point' if idx == 0 else \"\")\n",
        "    plt.plot(pos, compute_activation_time(new_start_pos, pos, new_speeds, new_change_positions), 'x', color='black')\n",
        "plt.xlabel('Position')\n",
        "plt.ylabel('Activation Time')\n",
        "plt.title('PINN Prediction on New Data with Specific Variable Speeds')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "# Save the plot\n",
        "plt.savefig('pinnplot/test_sample64datfast.png')\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "J8pnPwNgArNc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}